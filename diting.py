#! /usr/bin/env python3

import os
import sys
import argparse
from shutil import copy
from multiprocessing import Pool

__author__ = "Xue Chunxu; Heyu Lin"
__contact__ = "xuechunxu@outlook.com; heyu.lin@student.unimelb.edu.au"
__version__ = "0.3"

parser = argparse.ArgumentParser()
parser.add_argument('-r', '--reads', metavar='input_reads', dest='r',
                    type=str, required=True,
                    help='folder containing reads to be used as input')
parser.add_argument('-o', '--outdir', metavar='output_dir', dest='o',
                    type=str, required=True,
                    help='output directory')
parser.add_argument('-a', '--assembly', metavar='metagenomic_assembly', dest='a',
                    type=str,
                    help='folder containing metagenomic assemblies corresponding to provided reads, \
                    which should have the same base name as the reads')
parser.add_argument('-n', '--threads', metavar='threads', dest='n',
                    type=int, default=4,
                    help='threads that will be used')
parser.add_argument('--noclean', metavar='no_cleaning', dest='nc',
                    nargs="?", const=True, default=False,
                    help='The sam files would be retained if this flag was used')
args = parser.parse_args()


def make_dir(directory):
    if not os.path.exists(directory):
        os.mkdir(directory)


def remove_dir(directory):
    if os.path.exists(directory):
        os.removedirs(directory)

def reads_assembly(reads1, reads2, threads, output):
    cmd_para = [
                'megahit',
                '-1', reads1,
                '-2', reads2,
                '-o', output,
                '-t', str(threads)
                ]
    cmd = ' '.join(cmd_para)
    try:
        print("\n" + 'Metagenomic Assembly'.center(50, '*'))
        print(cmd + '\n')
        os.system(cmd)
    except:
        print("\nSomething went wrong when assembling metagenomic reads!")


def prodigal_meta(fasta, basename, outdir):
    cmd_para = [
                'prodigal', '-q',
                '-i', fasta,
                '-p', 'meta',
                '-a', os.path.join(outdir, basename + '.faa'),
                '-d', os.path.join(outdir, basename + '.ffn'),
                '-o', os.path.join(outdir, basename + '.gbk')
                ]
    cmd = ' '.join(cmd_para)
    try:
        print("\n" + 'ORFs prediction'.center(50, '*'))
        print(cmd + '\n')
        os.system(cmd)
    except:
        print("\nSomething wrong with prodigal annotation!")


def bwa_index(assembly, output):
    cmd_para = [
                'bwa index',
                '-p', output,
                assembly
                ]
    cmd = ' '.join(cmd_para)
    try:
        print("\n" + 'bwa index'.center(50, '*'))
        print(cmd + '\n')
        os.system(cmd)
    except:
        print("\nSomething wrong with bwa index!")


def bwa_mem(index_file, reads1, reads2, output, threads):
    cmd_para = [
                'bwa mem',
                '-t', str(threads),
                '-v 2',  # only show warnings and errors
                index_file,
                reads1,
                reads2,
                '>', output
                ]
    cmd = ' '.join(cmd_para)
    try:
        print("\n" + 'bwa mem'.center(50, '*'))
        print(cmd + '\n')
        os.system(cmd)
    except:
        print("\nSomething wrong with bwa_mem!")


def pileup(sam, output):
    cmd_para = [
                'pileup.sh',
                'usejni=t',
                'in={}'.format(sam),
                'out={}'.format(output)
                ]
    cmd = ' '.join(cmd_para)
    try:
        print("\n" + 'Calculate coverage depths - pileup'.center(50, '*'))
        print(cmd + '\n')
        os.system(cmd)
    except:
        print("\nSomething wrong with pileup.sh!")


def gene_relative_abun(pileup_file, basename, out_dir):
    """
    Calculate relative abundance of genes in a file generated by BBMap pileup

    :param pileup_file: coverage depths of genes generated by BBMap pileup
    :param basename: basename of a sample that will be calculated
    :param out_dir: output directory
    :return: None
    """
    print("\n" + 'Gene relative abundance'.center(50, '*'))
    total_ave_fold = float(0)
    file_out = os.path.join(out_dir, basename + '.abundance')
    with open(file_out, 'a') as fo:
        fo.write("#ID\tgene_abundance\n")
    with open(pileup_file) as fi:
        for line in fi:
            if line.startswith('#ID'):
                continue
            else:
                ave_fold = line.split('\t')[1]
                total_ave_fold += float(ave_fold)
    with open(pileup_file) as fi:
        for line in fi:
            if line.startswith('#ID'):
                continue
            else:
                gene_id = line.split('\t')[0]
                ave_fold = line.split('\t')[1]
                gene_abund = float(ave_fold) / float(total_ave_fold)
                with open(file_out, 'a') as fo:
                    fo.write(gene_id + "\t" + str(gene_abund) + "\n")


def ko_list_parser(ko_list):
    """
    parse ko_list file into a dict object

    :param ko_list: path of the file ko_list
    :return: a dictionary mapping knum to threshold and score_type
    :rtype: dict
    """
    ko_dic = {}  # { knum : [threshold, score_type] }
    with open(ko_list) as fi:
        next(fi)  # skip the first line (header)
        for line in fi:
            knum, threshold, score_type = line.split('\t')[0:3]
            ko_dic[knum] = [threshold, score_type]
    return ko_dic


def run_hmmsearch(paras):
    (threshold_method, threshold, output, hmm_db, faa) = paras
    cmd_para = [
        'hmmsearch',
        threshold_method, threshold,
        '--cpu', '1',
        '--tblout', output,
        hmm_db,
        faa
    ]
    cmd = ' '.join(cmd_para)
    try:
        # print(cmd + '\n')
        os.system(cmd)
    except:
        print("\nSomething wrong with KEGG hmmsearch!")


def kegg_annotation(faa, basename, out_dir, db_dir, ko_dic, threads):
    print("\n" + 'KEGG annotation for {}'.format(basename).center(50, '*'))
    paras = []  # Build a parameter list for multiprocessing

    for knum, info in ko_dic.items():
        output = os.path.join(out_dir, knum + '.' + str(basename) + '.hmmout')
        hmm_db = os.path.join(db_dir, 'profiles', knum + '.hmm')
        if info[1] == 'full':
            threshold_method = '-T'
        elif info[1] == 'domain':
            threshold_method = '--domT'
        else:
            threshold_method = '-E'
            info[0] = '1e-5'
        paras.append((threshold_method, info[0], output, hmm_db, faa))

    process = Pool(threads)
    process.map(run_hmmsearch, paras)


# merge kegg annotations into one file
def merge_ko(input_dir, output):
    print("\n" + 'merge KEGG annotations'.center(50, '*'))
    ko_merged_dict = {}  # { basename + gene_id : abundance }
    with open(output, 'w') as fo:
        fo.write('#sample\tgene_id\tk_number\n')
    for hmmout_file in os.listdir(input_dir):  # K00039.sample1.hmmout
        if hmmout_file.endswith('.hmmout'):
            basename = hmmout_file.rsplit('.')[1]
            hmmout_file_path = os.path.join(input_dir, hmmout_file)
            with open(hmmout_file_path, 'r') as fi:
                for line in fi:
                    if not line.startswith('#'):
                        gene_id, accession, k_number = line.split()[0:3]
                        key = str(basename) + '+' + str(gene_id)
                        ko_merged_dict[key] = k_number
                        with open(output, 'a') as fo:
                            fo.write(basename + '\t' + gene_id + '\t' + k_number + '\n')
    return ko_merged_dict


# merge gene relative abundance table with gene kegg annotation table
def merge_abun_ko(abun_table_dir, kegg_tab_dict, output):
    print("\n" + 'merge abundance table with kegg table'.center(50, '*'))
    with open(output, 'w') as fo:
        fo.write('#sample\tk_number\trelative_abundance\tgene_id\n')
    abun_tab_dict = {}
    for abun in os.listdir(abun_table_dir):
        if abun.endswith('.abundance'):
            basename = abun.rsplit('.', 1)[0]
            abun_path = os.path.join(abun_table_dir, abun)
            with open(abun_path) as fi:
                next(fi)
                for line in fi:
                    line = line.strip('\n')
                    gene_id, abundance = line.split('\t')
                    key = str(basename) + '+' + str(gene_id)
                    abun_tab_dict[key] = abundance

    for key in sorted(kegg_tab_dict.keys()):
        sample, gene_id = key.rsplit('+', 1)
        k_number = kegg_tab_dict[key]
        abundance = abun_tab_dict[key]
        with open(output, 'a') as fo:
            fo.write(sample + '\t' + k_number + '\t' + abundance + '\t' + gene_id + '\n')


# accessory-scripts/KEGG-decoder_meta.py
def kegg_decoder(input_tab, output):
    print("\n" + 'kegg decoder'.center(50, '*'))
    self_script_pathway = sys.path[0]
    kegg_decoder_meta_py = os.path.join(self_script_pathway, 'accessory-scripts', 'KEGG-decoder_meta.py')
    cmd_para = [
                'python',
                kegg_decoder_meta_py,
                input_tab,
                output
                ]
    cmd = ' '.join(cmd_para)
    os.system(cmd)


def check_reads_assembly(assembly_dir, reads_dir):
    """
    Check if the assembly provided can match corresponding reads pairs

    :param str assembly_dir: directory containing metagenomic assemblies in fasta format
    :param str reads_dir: directory containing metagenomic paired-end reads
    :return: basenames of input files, suffix of the reads, suffix of the assembly
    :rtype: tuple
    :raises FileNotFoundError: if the corresponding reads pairs cannot be found or are not complete

    """
    basenames = []
    reads_suf = ''
    assembly_suf = ''

    for fa in os.listdir(assembly_dir):
        basename, assembly_suf = fa.rsplit('.', 1)
        basenames.append(basename)

        reads_dir_basename = os.path.join(reads_dir, basename)

        if os.path.exists(reads_dir_basename + '_1.fq') and os.path.exists(reads_dir_basename + '_2.fq'):
            reads_suf = '.fq'
        elif os.path.exists(reads_dir_basename + '_1.fastq') and os.path.exists(reads_dir_basename + '_2.fastq'):
            reads_suf = '.fastq'
        elif os.path.exists(reads_dir_basename + '_1.fq.gz') and os.path.exists(reads_dir_basename + '_2.fq.gz'):
            reads_suf = '.fq.gz'
        elif os.path.exists(reads_dir_basename + '_1.fastq.gz') and os.path.exists(reads_dir_basename + '_2.fastq.gz'):
            reads_suf = '.fastq.gz'
        else:
            raise FileNotFoundError('Failed to find the corresponding paired-end reads to {}'.format(fa))

    return basenames, reads_suf, assembly_suf


def check_reads(reads_dir):
    """
    Check if the assembly provided can match corresponding reads pairs

    :param str reads_dir: directory containing metagenomic paired-end reads
    :return: basenames of input files, suffix of the reads
    :rtype: tuple
    :raises FileNotFoundError: if the reads provided in the input directory are not in pairs

    """
    basenames = []
    reads_suf = ''

    for read in os.listdir(reads_dir):
        if read.endswith('_1.fq'):
            basename = read.rsplit('_', 1)[0]
            basenames.append(basename)
            reads_suf = '.fq'
            if not os.path.exists(os.path.join(reads_dir, basename) + '_2.fq'):
                raise FileNotFoundError('Failed to find the corresponding reverse reads to {}'.format(read))
        elif read.endswith('_1.fastq'):
            basename = read.rsplit('_', 1)[0]
            basenames.append(basename)
            reads_suf = '.fastq'
            if not os.path.exists(os.path.join(reads_dir, basename) + '_2.fastq'):
                raise FileNotFoundError('Failed to find the corresponding reverse reads to {}'.format(read))
        elif read.endswith('_1.fastq.gz'):
            basename = read.rsplit('_', 1)[0]
            basenames.append(basename)
            reads_suf = '.fastq.gz'
            if not os.path.exists(os.path.join(reads_dir, basename) + '_2.fastq.gz'):
                raise FileNotFoundError('Failed to find the corresponding reverse reads to {}'.format(read))
        elif read.endswith('_1.fq.gz'):
            basename = read.rsplit('_', 1)[0]
            basenames.append(basename)
            reads_suf = '.fq.gz'
            if not os.path.exists(os.path.join(reads_dir, basename) + '_2.fq.gz'):
                raise FileNotFoundError('Failed to find the corresponding reverse reads to {}'.format(read))

    return basenames, reads_suf


def main():

    """
    Define variables
    """
    READS_DIR = args.r  # directory for input fastq reads
    OUT_DIR = args.o  # directory for output results
    THREADS = args.n  # threads will be used
    ASSEMBLY_DIR = os.path.join(OUT_DIR, 'Assembly')  # directory for assembled contigs
    ASSEMBLY_TMP = os.path.join(OUT_DIR, 'Assembly')  # directory for megahit temporary files
    PRODIGAL_DIR = os.path.join(OUT_DIR, 'ORFs')  # directory for predicted ORFs
    BBMAP_DIR = os.path.join(OUT_DIR, 'BBMap')  # directory for predicted ORFs
    GENE_ABUN_DIR = os.path.join(OUT_DIR, 'Abundance')  # directory for gene relative abundance
    KEGG_DIR = os.path.join(OUT_DIR, 'kegg_annotation')  # directory for KEGG annotations
    ROOT_DIR = sys.path[0]
    KODB_DIR = os.path.join(ROOT_DIR, 'kofam_database')  # downloaded kofam_database folder from KEGG website

    BASENAMES = []  # input files basename list
    READS_SUF = ''  # suffix of input reads
    ASSEMBLY_SUF = 'fa'  # suffix of assemblies

    make_dir(OUT_DIR)

    """
    Check assemblies / reads & Get input basename
    """
    if args.a:
        # If the corresponding assembly was provided, check if the corresponding reads can be found
        ASSEMBLY_DIR = args.a
        BASENAMES, READS_SUF, ASSEMBLY_SUF = check_reads_assembly(ASSEMBLY_DIR, READS_DIR)
    else:
        # If the corresponding assembly was NOT provided, check if the reads are in pairs
        BASENAMES, READS_SUF = check_reads(READS_DIR)

    """
    Check ko hmm database exists and has been formatted
    """
    # check_kodb(KODB_DIR)

    """
    Megahit Assembly
    """
    if not args.a:
        for bn in BASENAMES:
            remove_dir(ASSEMBLY_TMP)  # make sure the output folder for Megahit does not exist
            reads1 = os.path.join(READS_DIR, bn) + '_1' + READS_SUF
            reads2 = os.path.join(READS_DIR, bn) + '_2' + READS_SUF
            reads_assembly(reads1, reads2, THREADS, ASSEMBLY_TMP)  # Megahit will create the output folder automatically
            assembly_ori = os.path.join(ASSEMBLY_TMP, 'final.contigs.fa')
            assembly_tar = os.path.join(ASSEMBLY_DIR, bn + '.fa')
            copy(assembly_ori, assembly_tar)
    remove_dir(ASSEMBLY_TMP)  # clean up the Megahit temporary folder

    """
    Prodigal Prediction
    """
    make_dir(PRODIGAL_DIR)
    for bn in BASENAMES:
        fasta = os.path.join(ASSEMBLY_DIR, bn + '.fa')
        prodigal_meta(fasta, bn, PRODIGAL_DIR)

    """
    BBMap
    """
    bwa_index_dir = os.path.join(BBMAP_DIR, 'bwa_index')
    mapping_dir = os.path.join(BBMAP_DIR, 'mapping')
    pileup_dir = os.path.join(BBMAP_DIR, 'coverage')
    make_dir(BBMAP_DIR)
    make_dir(bwa_index_dir)
    make_dir(mapping_dir)
    make_dir(pileup_dir)

    for bn in BASENAMES:
        fasta = os.path.join(PRODIGAL_DIR, bn + '.ffn')
        index_file = os.path.join(bwa_index_dir, bn)
        reads1 = os.path.join(READS_DIR, bn + '_1' + READS_SUF)
        reads2 = os.path.join(READS_DIR, bn + '_2' + READS_SUF)
        sam = os.path.join(mapping_dir, bn + '.sam')
        pileup_out = os.path.join(pileup_dir, bn + '.pileup')

        bwa_index(fasta, index_file)  # build index for genes
        bwa_mem(index_file, reads1, reads2, sam, THREADS)  # map reads to genes
        pileup(sam, pileup_out)  # calculate coverage depths of every gene

        if not args.nc:  # the sam file will be removed as soon as it has been parsed due to it's large volume generally
            os.remove(sam)
    
    """
    Gene relative abundance
    """
    make_dir(GENE_ABUN_DIR)
    pileup_dir = os.path.join(BBMAP_DIR, 'coverage')
    for bn in BASENAMES:
        pileup_out = os.path.join(pileup_dir, bn + '.pileup')
        gene_relative_abun(pileup_out, bn, GENE_ABUN_DIR)

    """
    Resolve ko_list file into dictionary
    """
    ko_list = os.path.join(KODB_DIR, 'ko_list')
    ko_dic = ko_list_parser(ko_list)

    """
    KEGG annotation by hmmsearch
    """
    make_dir(KEGG_DIR)
    kegg_pieces_dir = os.path.join(KEGG_DIR, 'pieces')  # containing KEGG annotations of every knum
    make_dir(kegg_pieces_dir)
    for bn in BASENAMES:
        faa = os.path.join(PRODIGAL_DIR, bn + '.faa')
        kegg_annotation(faa, bn, kegg_pieces_dir, KODB_DIR, ko_dic, THREADS)

    """
    Merge KEGG annotations
    """
    ko_merged_tab = os.path.join(KEGG_DIR, 'ko_merged.txt')
    ko_merged_dict = merge_ko(kegg_pieces_dir, ko_merged_tab)

    """
    Merge KEGG annotations and gene relative abundances
    """
    ko_abun_merged_tab = os.path.join(KEGG_DIR, 'ko_abun.txt')
    merge_abun_ko(GENE_ABUN_DIR, ko_merged_dict, ko_abun_merged_tab)

    """
    Invoke KEGG-decoder_meta.py
    """
    final_output = os.path.join(OUT_DIR, 'pathways_relative_abundance.tab')
    kegg_decoder(ko_abun_merged_tab, final_output)


if __name__ == '__main__':
    main()
